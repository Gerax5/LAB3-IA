{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Laboratorio 3 IA\n",
    "#### Enlace a github: https://github.com/Gerax5/LAB3-IA\n",
    "Integrantes:\n",
    "- Gerardo Pineda #22808\n",
    "- Francis Aguilar #22243\n",
    "- Angela Garcia #22869\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1\n",
    "\n",
    "1. Descenso de gradiente: método que calcula el gradiente de la función de perdida respecto a todos los datos de entrenamiento en cada iteración y actualiza los parámetros en la dirección opuesta al gradiente para minimizar la perdida. Su ventaja es que converge hacia el mínimo global si la función de pérdida es convexa. Y su desventaja es que es computacionalmente costoso cuando se usan grandes conjuntos de datos.\n",
    "\n",
    "2. Descenso de gradiente por mini batches: en este método los datos de entrenamiento se dividen en lotes más pequeños (mini batches) y el gradiente se calcula y los parámetros se actualizan para cada lote. Su ventaja es que reduce la carga computacional al trabajar con lotes pequeños. Pero su desventaja es que puede ser menos preciso que el descenso de gradiente completo, debido a la variabilidad de lotes.\n",
    "\n",
    "3. Desceso de gradiente estocástico: en este enfoque, se selecciona aleatoriamente un solo ejemplo de entrenamiento en cada iteración para calcular el gradiente y actualizar los parámetros. Su ventaja es que converge más rapido en muchos casos, esto debido a las actualizaciones más frecuentes. Y su desventaja es que puede ser más \"ruidoso\" y menos estable debido a la aleatoriedad en la selección de ejemplos.\n",
    "\n",
    "Fuentes de información   \n",
    "Ferreira, E. V. Gradiente descendente. Blanco, P. A. (2016)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------\n",
    "# 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare y contraste técnicas de extracción de features (feature extraction)  y selección de features (feature selection) en machine learning. De ejemplos de escenarios donde cada técnica sería más apropiada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Técnicas de extracción de features:\n",
    "- Análisis de componentes principales (PCA), para reducir la dimensionalidad al encontrar nuevas variables\n",
    "- Transformada de Fourier, esta convierte los datos temporales o espaciales a su represión en frecuentcia.\n",
    "- Transformación de Wavelet, esta es similar a la de Fourier, pero da una representacion en el dominio de tiempo-frecuencia.\n",
    "- Modelos de tópicos (LDA),  para el procesamiento de texto, identifica los \"temas latentes\" en los documentos, extrayendo las palabras basadas en la ocurrencia de las palabras.\n",
    "- Autoencoders, este se usa en redes neuronales para aprender codificaciones de los datos, se usa en imagenes y datos de alta dimensión.\n",
    "- Análisis de regresión, para predecir una variable dependiente a partir de la variable independiente.\n",
    "\n",
    "Técnicas de selección de features:\n",
    "- Método de filtrado, este selecciona features basados en estadisticas básicas. Como chi-cuadrado y información mutua.\n",
    "- Método wrapperm este usa algoritmos de machine learning para seleccionar subconjuntos de features y evaluar su rendimiento.\n",
    "- Método embedded, esta técnica incorpora la seleccion de features durante el proceso del entrenamiento del modelo.\n",
    "\n",
    "\n",
    "Ejemplos de escenarios donde cada técnica sería más apropiada:\n",
    "\n",
    "- (PCA): Se tiene un conjunto de datos con muchas variables predictoras de diferentes sensores de fabrica. Tiene mucha redundancia y la correlacion entre estas variables y se queire reducir la dimensionalidad para mejorar el rendimiento del modelo y simplificar el analisis sin perder mucha informacion. Se usar PCA para reducir la dimensionalidad del conjunto de datos. \n",
    "\n",
    "- Transformada de Fourier: Se esta trabajando con datos de señal de audio o vibración que vienen de una maquinaria en una línea de producción y se quiere analizar las frecuencias de las señales para identificar patrones de fallas. Se usa la transformada de Fourier para convertir las señales en el dominio de frecuencia y ver luego los patrones.\n",
    "\n",
    "- Transformada de Wavelet: Se esta analizando los datos de electroencelafografía para detectar anomalías del cerebro y estas no son estacionarias y cambian con el tiempo. La transformada de Wavelet es una técnica muy útil para el análisis de señales no estacionarias. Se usará la transformada de Wavelet para extraer información de las señales no estacionarias.\n",
    "\n",
    "- Modelos de tópicos: Se tiene una colección de articulos de noticias y se quiere organizar automaticamente los articulos en diferentes temas para facilitar la búsqueda y el análisis. Entonces se usa LDA para identificar los temas latentes en los articulos.\n",
    "\n",
    "- Autoencoders: Se tienen imagenes de alta resolucion y se quiere reducir la dimensionalidad para tareas de clasificacion de imagenes y deteccion de anomalías. Se usará el autoencoder para aprender una codificación de las imagenes.\n",
    "\n",
    "- Análisis de regresión: Se tienen datos historicos de ventas de una tienda y de quiere predecir las ventas futuras en función de variables futuras en funcion de variables independientes como el precio. Entonces se usa regresión lineal para predecir las promociones y condiciones economicas\n",
    "\n",
    "- Método de filtrado: Se esta trabajando con un problema de clasificacion de imagenes para detectar celulas cancerigenas en una muestra de tejidos y se tiene un conjunto de datos con muchas caracteristicas de imagenes como texturas, bordes y colores. Entonces se puede aplicar pruebas de chi-cuadrado y de información mutua para seleccionar las caracteristicas mas relevantes para el problema.\n",
    "\n",
    "- Método wrapper: se tiene un conjunto de datos con muchas variables y se quiere seleccionar el subconjunto optimo para maximizar la precisión del modelo para predecir el riesgo crediticio de los clientes de un banco, basado en datos financieros y demograficos. Entonces se usa un algorimo de machine learning como un clasificador de arboles de desición y un método de eliminación recursiva de features para seleccionar el subconjunto optimo de variables y mejore el rendimiento del modelo.\n",
    "\n",
    "- Método embedded: Se esta construyendo un modelo de predicción para evaluar la probabilidad de que un cliente compre en una tienda en línea basado en datos de comportamiento de navegación y datos demograficos. Entonces, se puede usar técnicas como L1 regularization en el entrenamiento del modelo para seleccionar las variables mas relevantes para el problema.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------\n",
    "# 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describa la arquitectura y el funcionamiento de un perceptrón de una sola capa (un tipo de red neuronal sin backpropagation). Explique cómo aprende y la forma en la que actualiza sus parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquitectura\n",
    "El perceptron de una sola capa tiene como arquitectura:\n",
    "* Tiene datos de entrada: (x_1,x_2,...,x_n)\n",
    "* El peso asociado con su entrada: (w_1,w_2,...,w_n)\n",
    "* la funcion de activacion f(x), que es la encargada de decidir la salida dependiendo de la suma ponderada\n",
    "* y la salida (y)\n",
    "### Como aprende\n",
    "Primero se incian los pezos en aleatorio o en 0, se utiliza cada muestra de entrenamiento con su salida real y predicha para actualizar los pesos. Lo que hace para aprende es ajustar los pesos y el bias, asi sucesivamnete hasta que se terminen las iteraciones o el error se minimice."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
